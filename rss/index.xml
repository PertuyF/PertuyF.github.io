<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Within the Black Hole]]></title><description><![CDATA[Coming soon!]]></description><link>https://PertuyF.github.io</link><image><url>/images/Blog_cover2.png</url><title>Within the Black Hole</title><link>https://PertuyF.github.io</link></image><generator>RSS for Node</generator><lastBuildDate>Fri, 14 Jul 2017 16:52:12 GMT</lastBuildDate><atom:link href="https://PertuyF.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Starting DeepLearning]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="quoteblock abstract">
<blockquote>
<div class="paragraph">
<p>The role of intuition</p>
</div>
</blockquote>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_role_of_intuition">The role of Intuition</h2>
<div class="sectionbody">
<div class="paragraph">
<p>I started reading and experimenting about <strong>Deep Learning</strong> not so long ago and I found a great discrepancy in the affordability of resources available to <em>naïve</em> learners.
I&#8217;ve met a similar situation in image processing, where explanations about how an algorithm works and what it does is too often limited to inapprehensible equations.</p>
</div>
<div class="paragraph">
<p>I must admit, I am not of the <em>math-oriented</em> type.
Well, at least I am not fond of math in the way it is taught by most mathematicians.
I need intuition to understand how a tool works and how I can use it.
And a good graphical representation is most of the time far more efficient for me than any equation.
For me, learning is all about building my own representation of things, that fits with what I already know.</p>
</div>
<div class="paragraph">
<p>Anyway, there are other people that feel the same. I know that because intuitive approaches tends to increase significantly over the web.
<a href="https://betterexplained.com/">Better Explained</a> is a good example, I would have dreamt to be taught math this way in school!</p>
</div>
<div class="paragraph">
<p>In short, I claim that getting intuition is how it works.
Intuition is <strong><em>FUNDAMENTAL</em></strong> to acquire knowledge.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_grabbing_intuition_about_deep_learning">Grabbing intuition about Deep Learning</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Hopefully, some people decided to created resources about Deep Learning that follow this philosophy.
These resources are meant to bring Deep Learning to anyone with minimal skills in informatics and enough curiosity.
They aim to help building intuition out of practical examples, and allow anyone to learn in a self-paced schedule.</p>
</div>
<div class="paragraph">
<p>There are two resources that exactly fit this description, and that I would like to share because of the outstanding quality of their content:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://cloud.google.com/blog/big-data/2017/01/learn-tensorflow-and-deep-learning-without-a-phd">DeepLearning without a PhD</a>, a 3 hours speech by <a href="https://plus.google.com/+MartinGorner">Martin Görner</a> (Google) that demonstrate how to build a Neural Network working with the famous MNIST dataset.
Several architectures are tested, demonstrating how to tune the network up to a <strong>Convolutional Neural Network (CNN)</strong> that achieves up to 99.5% accuracy (top 10 of best results for this dataset).
Final part is a demo of some <strong>Recurrent Neural Network (RNN)</strong> able to generate random text following the style of Shakespeare&#8217;s play, or the syntax of the Python code of Tensorflow itself.
Both the videos (short and long versions), the code, the slides and an interactive codelab of this excellent demonstration are available.</p>
</li>
<li>
<p><a href="http://course.fast.ai/index.html">Practical Deep Learning For Coders</a>, a 7 weeks formation by <a href="https://www.usfca.edu/data-institute/about-us/researchers">Jeremy Howard</a> (fast.ai, Data Institute at the University of San Francisco), freely available as a MOOC.
The whole course is covering <strong>CNN</strong>, demonstrating the use of pre-trained models, <strong>RNN</strong> and <strong>Natural Language Processing(NLP)</strong>.
Each week corresponds to a ~2H video, plus a Jupyter notebook and assignments.
Usually, students are encouraged to enter Kaggle competitions and play around with all resources available.
The website also has a nice and responsive forum with a growing community.
Part 2 of this course should be released in the next months, and I am sure it will be as amazing as Part 1.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The common aim of these two resources is to get to practice as soon as possible.
Only then dissect who does what, why and how.
The fastest way to build intuition is to observe the thing running (or literally stare at it), play with it and think about it.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_getting_practical_get_a_computer">Getting practical: get a computer</h2>
<div class="sectionbody">
<div class="paragraph">
<p>But, playing with <strong>Neural Networks</strong> is not exactly trivial, not if you don&#8217;t want to get bored very quickly.<br>
Why that?<br>
Because they&#8217;re hungry for computational power.</p>
</div>
<div class="paragraph">
<p>Well, they are not exactly monsters that will require thousands to be invested in your computer, they can run on pretty any system available these days.
But they can be so <strong>slooowwwwww&#8230;&#8203;</strong></p>
</div>
<div class="paragraph">
<p>The point is that Neural networks rely on matrix computations, with thousands of computations in parallel.
So depending on your hardware, you will be able to train a network in a few seconds.
Or to wait for <strong>hours</strong> (Seriously. Hours.) for the result.
And that&#8217;s why it is not trivial: to keep it playful you have to get some capable hardware, then set up your software properly before everything works.
Basically there are two options:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Rent a dedicated system</strong>, such as computation servers (which are getting cheaper and cheaper).
It seems to work quite well, but not everyone is willing to invest money in it.
I am not, so I will not detail this option any further, but it&#8217;s still a viable way to do things.</p>
</li>
<li>
<p><strong>Get your own system</strong>.
Hopefully, you don&#8217;t need an extreme CPU for that, because matrix computations are totally adapted to GPUs.
And GPUs are affordable and very well spread (Thank you Gamers!).
Almost any mid-range GPU will be able to get you started if needed, but there are definitely important criterions to be taken into account if you want to get serious job done.
 <a href="http://timdettmers.com/2017/04/09/which-gpu-for-deep-learning/">Which GPU to get for Deep Learning</a> is very nice article on this subject by Tim Dettmers. The author is very responsive, so do not hesitate to ask for more precisions in the comments.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_getting_practical_make_it_run">Getting practical: make it run!</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Once you get a suitable system, it&#8217;s time to choose the software and to get it running.
There is certainly no <em>best</em> language for Deep Learning, and I will not pretend to recommend any.
On my side I use <strong>Python</strong>, and obviously the resources I am talking about are using Python too.</p>
</div>
<div class="paragraph">
<p>Many Python libraries are available for Deep Learning, and the choice might be difficult here also.
I think <a href="https://keras.io/">Keras</a> is a good pick, as it is unifying some popular frameworks so you can jump from one to another very easily.
<a href="https://www.tensorflow.org/">TensorFlow</a> and <a href="http://deeplearning.net/software/theano/#">Theano</a> are fully supported, and <a href="https://docs.microsoft.com/en-us/cognitive-toolkit/">CNTK</a> and <a href="http://mxnet.io/">MXNET</a> are coming right now (beta).
Reviews of the different frameworks are available online (for example <a href="https://indico.io/blog/python-deep-learning-frameworks-reviewed/">here</a>).</p>
</div>
<div class="paragraph">
<p>There are plenty tutorial and use cases available online that use Keras to help at start.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_next_step">The next step</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The great thing about Deep Learning is that there is so much to understand, to explore about it.
So that any tiny idea could lead to discover useful notions.
These times will probably be referred to as the golden age of Deep Learning a few years ahead, and the most people getting involved, the more progress to be done, so let&#8217;s get involved!</p>
</div>
<div class="paragraph">
<p>Basically I am not very far in the process.
I integrated basic notions about neural networks: basic architectures, main parameters to tune, how to detect common problems and how to improve the results.</p>
</div>
<div class="paragraph">
<p>I feel that I know just enough to understand I know nothing (you&#8217;re not alone, John Snow).
I like to think about <strong>Deep Learning</strong> as a <strong>Black Hole</strong>: everyone understand it is extremely powerful, some people have an idea of how to use it, but no one knows for sure what&#8217;s going on inside.</p>
</div>
<div class="paragraph">
<p>On my side I&#8217;ll try to keep a methodical, scientific, approach to investigate this field, and communicate about it to benefit from peer review.
I do not plan to look at scientific literature before testing an idea, but in a second time just to ensure I am not re-discovering the wheel.
What I expect is to get insights from other people and to exchange ideas, so tell me if you think differently, or if you experimented similar things.</p>
</div>
<div class="paragraph">
<p>All I want is to learn from our discussions.</p>
</div>
</div>
</div>]]></description><link>https://PertuyF.github.io/2017/07/13/Starting-Deep-Learning.html</link><guid isPermaLink="true">https://PertuyF.github.io/2017/07/13/Starting-Deep-Learning.html</guid><category><![CDATA[DeepLearning]]></category><category><![CDATA[Python]]></category><category><![CDATA[MOOC]]></category><category><![CDATA[Blog]]></category><dc:creator><![CDATA[Fabien Pertuy]]></dc:creator><pubDate>Thu, 13 Jul 2017 00:00:00 GMT</pubDate></item><item><title><![CDATA[Hello World!]]></title><description><![CDATA[<div class="quoteblock abstract">
<blockquote>
<div class="paragraph">
<p>First blog, first post</p>
</div>
<div class="paragraph">
<p>Purpose</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>I come from Biology and made my way toward imaging and image processing, entering the field of Bioinformatics a few years ago.
I started to use <strong>Python</strong> for this purpose and quickly grew fond of this wonderful language whose impact is hugely increasing in the scientific community.<br>
Being familiar with biostatistics and data analyses, I was curious of learning more general notions related to Data Sciences.
Doing so I discovered what brings me there, <strong>machine learning</strong>.</p>
</div>
<div class="paragraph">
<p>Machine learning is not that common, at least not yet, in fundamental research for Biology.
I found that a number of tools I already used for image processing (the Numpy/Scipy ecosytem) where actually behind some of the main Python libraries for Data Sciences, like Pandas and Scikit-learn.<br>
Nevertheless it was an entirely new field to me, and even if I already knew some tools I needed theory.
I learned the basics of machine learning with MOOCs (especially the nice <a href="https://www.udacity.com/course/intro-to-machine-learning--ud120">"intro to machine learning"</a> from Udacity), and experimenting using <a href="https://www.kaggle.com/">Kaggle</a> in the meanwhile.<br></p>
</div>
<div class="paragraph">
<p>Then I reached the part on <strong>Neural Networks</strong>&#8230;&#8203;<br>
I must say that I am fascinated by these things, they are getting all my focus right now and they definitely are what triggered that blog.</p>
</div>
<div class="paragraph">
<p>My purpose here is to share what I learn and experiment, step by step, starting with Neural Networks.<br></p>
</div>]]></description><link>https://PertuyF.github.io/2017/05/31/Hello-World.html</link><guid isPermaLink="true">https://PertuyF.github.io/2017/05/31/Hello-World.html</guid><category><![CDATA[Introduction]]></category><category><![CDATA[Python]]></category><category><![CDATA[Machine_Learning]]></category><category><![CDATA[Deep_Learning]]></category><category><![CDATA[Data_Science]]></category><dc:creator><![CDATA[Fabien Pertuy]]></dc:creator><pubDate>Wed, 31 May 2017 00:00:00 GMT</pubDate></item></channel></rss>